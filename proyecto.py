import streamlit as st
st.set_page_config(layout="wide")
import spacy
import tensorflow as tf
import tensorflow.keras as tf_keras
import re
import nltk
import numpy as np
import pickle
import os
import sys
import types
from gensim.models import Word2Vec
from nltk.corpus import stopwords
from nltk import word_tokenize
from nltk.stem.wordnet import WordNetLemmatizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.initializers import Orthogonal
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
import pandas as pd
import plotly.express as px

# Usamos directamente la librer√≠a oficial de OpenAI 
from openai import OpenAI

try:
    import keras 
except ModuleNotFoundError:
    keras = types.ModuleType("keras")
    keras.__dict__.update(tf_keras.__dict__)
    sys.modules['keras'] = keras
    sys.modules['keras.src'] = tf_keras
    if hasattr(tf_keras, "preprocessing"):
        sys.modules['keras.src.preprocessing'] = tf_keras.preprocessing
        if hasattr(tf_keras.preprocessing, "text"):
            sys.modules['keras.src.preprocessing.text'] = tf_keras.preprocessing.text

# ---------------------------------------------------------------------
# RECURSOS NLTK
# ---------------------------------------------------------------------
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')

try:
    stopwords_en = stopwords.words('english')
    lemmatizer = WordNetLemmatizer()
except LookupError:
    nltk.download('stopwords')
    nltk.download('punkt')
    nltk.download('wordnet')
    stopwords_en = stopwords.words('english')
    lemmatizer = WordNetLemmatizer()

# ---------------------------------------------------------------------
# CARGA DEL MODELO DE spaCy 
# ---------------------------------------------------------------------
try:
    nlp = spacy.load('en_core_web_lg')
except Exception:
    nlp = None

# ---------------------------------------------------------------------
# CARGA DEL MODELO WORD2VEC
# ---------------------------------------------------------------------
w2v_model = Word2Vec.load('word2vec.model')
DIM_W2V = w2v_model.vector_size  # dimensi√≥n real del embedding (seguro ~100)

CATEGORIAS = [
    'ACCOUNT', 'ORDER', 'REFUND', 'INVOICE', 'PAYMENT',
    'FEEDBACK', 'CONTACT', 'SHIPPING_ADDRESS', 'DELIVERY',
    'CANCELLATION_FEE', 'NEWSLETTER'
]

# =====================================================================
# FUNCIONES DE PLN
# =====================================================================

def vectorizar(texto: str) -> np.ndarray:
    texto = texto.lower()
    texto = re.sub(r'([^0-9A-Za-z \t])', ' ', texto)
    tokens = word_tokenize(texto)
    tokens = [
        lemmatizer.lemmatize(token)
        for token in tokens
        if token not in stopwords_en
    ]
    vectores = [w2v_model.wv[token] for token in tokens if token in w2v_model.wv]
    if len(vectores) == 0:
        return np.zeros(DIM_W2V)
    return np.mean(vectores, axis=0)


def ajustar_dim(vec: np.ndarray, dim_objetivo: int) -> np.ndarray:
    """
    Ajusta un vector 1D al tama√±o dim_objetivo:
    - si es m√°s grande, lo recorta,
    - si es m√°s peque√±o, lo rellena con ceros.
    """
    actual = vec.shape[0]
    if actual == dim_objetivo:
        return vec
    if actual > dim_objetivo:
        return vec[:dim_objetivo]
    # actual < dim_objetivo
    padding = np.zeros(dim_objetivo - actual)
    return np.concatenate([vec, padding])

def predecir(modelo, texto: str) -> dict:
    """
    Devuelve un diccionario {categor√≠a: probabilidad} para un comentario.
    - Para modelos Keras (FNN/CNN) se adapta al input_shape del modelo.
    - Para modelos sklearn se usa directamente el vector Word2Vec.
    """
    base_vec = vectorizar(texto)  # 1D, largo = DIM_W2V

    # Modelos Keras (FNN / CNN)
    if isinstance(modelo, tf.keras.Model):
        input_shape = modelo.input_shape  # p.ej. (None, 300) o (None, 100, 1)
        rank = len(input_shape)

        # FNN
        if rank == 2:
            input_dim = input_shape[1]
            x = np.zeros((1, input_dim), dtype=np.float32)
            L = min(base_vec.size, input_dim)
            x[0, :L] = base_vec[:L]
            probs = modelo.predict(x, verbose=0)[0]

        # CNN
        elif rank == 3:
            seq_len = input_shape[1]
            channels = input_shape[2]
            x = np.zeros((1, seq_len, channels), dtype=np.float32)

            flat = base_vec  
            if channels == 1:
                L = min(flat.size, seq_len)
                x[0, :L, 0] = flat[:L]
            else:
                needed = seq_len * channels
                tmp = np.zeros(needed, dtype=np.float32)
                L = min(flat.size, needed)
                tmp[:L] = flat[:L]
                x[0, :, :] = tmp.reshape(seq_len, channels)
            probs = modelo.predict(x, verbose=0)[0]

        else:
            # Caso raro: cualquier otra cosa, usamos fallback simple
            x = base_vec.reshape(1, -1)
            probs = modelo.predict(x, verbose=0)[0]

    # Modelos sklearn con predict_proba (SVM, etc.)
    elif hasattr(modelo, "predict_proba"):
        x = base_vec.reshape(1, -1)
        probs = modelo.predict_proba(x)[0]

    # Fallback gen√©rico
    else:
        x = base_vec.reshape(1, -1)
        y = modelo.predict(x)
        if isinstance(y, np.ndarray):
            cls = int(np.argmax(y))
        else:
            cls = int(y[0])
        probs = np.zeros(len(CATEGORIAS))
        probs[cls] = 1.0

    probs = np.array(probs, dtype=float)
    if probs.sum() > 0:
        probs = probs / probs.sum()

    scores = dict(zip(CATEGORIAS, probs))
    return scores


def predecir_batch(modelo, texto: str) -> str:
    """
    Devuelve la categor√≠a final para un comentario (para clasificaci√≥n en CSV).
    Usa la misma l√≥gica de construcci√≥n de input que predecir().
    """
    base_vec = vectorizar(texto)

    # üîπ Modelos Keras
    if isinstance(modelo, tf.keras.Model):
        input_dim = modelo.input_shape[-1]
        x = np.zeros((1, input_dim), dtype=np.float32)
        L = min(base_vec.size, input_dim)
        x[0, :L] = base_vec[:L]
        probs = modelo.predict(x, verbose=0)[0]
        idx = int(np.argmax(probs))
        return CATEGORIAS[idx]

    # üîπ Modelos sklearn con probas
    if hasattr(modelo, "predict_proba"):
        x = base_vec.reshape(1, -1)
        probs = modelo.predict_proba(x)[0]
        idx = int(np.argmax(probs))
        return CATEGORIAS[idx]

    # üîπ Fallback
    x = base_vec.reshape(1, -1)
    y = modelo.predict(x)[0]
    if isinstance(y, str):
        return y
    try:
        return CATEGORIAS[int(y)]
    except Exception:
        return str(y)

class CustomLSTM(tf.keras.layers.LSTM):
    """LSTM custom para cargar modelos antiguos que usaban time_major."""
    def __init__(self, *args, **kwargs):
        if 'time_major' in kwargs:
            kwargs.pop('time_major')
        super(CustomLSTM, self).__init__(*args, **kwargs)


def generar_texto(semilla, n_lineas, modelo, tokenizer, max_len=20):
    """Generador simple de texto a partir de una semilla."""
    resultado = []
    for _ in range(n_lineas):
        texto = []
        semilla_actual = semilla
        for _ in range(max_len):
            codificado = tokenizer.texts_to_sequences([semilla_actual])
            codificado = pad_sequences(codificado, maxlen=max_len - 1, padding='pre')
            y_pred = np.argmax(modelo.predict(codificado, verbose=0), axis=-1)[0]
            palabra_predicha = ''
            for palabra, indice in tokenizer.word_index.items():
                if indice == y_pred:
                    palabra_predicha = palabra
                    break
            if not palabra_predicha:
                break
            semilla_actual += ' ' + palabra_predicha
            texto.append(palabra_predicha)
        resultado.append(' '.join(texto))
    return resultado

# =====================================================================
# INTERFAZ STREAMLIT
# =====================================================================

st.title("Sistema NLP para Clasificaci√≥n de Mensajes de Clientes")

opcion = st.sidebar.selectbox(
    "Selecciona una opci√≥n",
    (
        "Inicio",
        "N-Gramas",
        "T-SNE",
        "Modelos",
        "ChatGPT",
        "Marco legal y t√©cnico"
    )
)

# ---------------------------------------------------------------------
# INICIO
# ---------------------------------------------------------------------
if opcion == "Inicio":
    st.header("Proyecto de Integraci√≥n Tecnol√≥gica Atenci√≥n a Clientes con IA")
    st.markdown("""Luis Atristain Alfaro, Efren Flores Porras, Gabriela Shaooli Cassab, Carlo Folgori Jacobo, Patricio Fern√°ndez Paill√©s, Oscar Rodr√≠guez Alc√°ntara y Miguel Angel Zamora del Castillo 
""")
    st.subheader("Descripci√≥n general")
    st.write("""
Este proyecto implementa un sistema de **Procesamiento de Lenguaje Natural (PLN)** para clasificar
mensajes de soporte al cliente en 11 categor√≠as (ACCOUNT, ORDER, REFUND, INVOICE, PAYMENT,
FEEDBACK, CONTACT, SHIPPING_ADDRESS, DELIVERY, CANCELLATION_FEE, NEWSLETTER).

La idea central es que la empresa pueda:
- Priorizar casos cr√≠ticos,
- Canalizar correctamente cada ticket,
- Mejorar la experiencia del usuario,
- Y todo esto **bajo supervisi√≥n humana**, respetando el marco jur√≠dico y √©tico.
    """)

    st.subheader("Componentes de la soluci√≥n")
    st.markdown("""
1. **Preprocesamiento de texto**  
   Limpieza, tokenizaci√≥n, eliminaci√≥n de stopwords y lematizaci√≥n (NLTK + spaCy).

2. **Vectorizaci√≥n**  
   Representaci√≥n de mensajes con **Word2Vec (300 dimensiones)** entrenado en el dataset.

3. **Modelos de clasificaci√≥n**  
   - Modelos cl√°sicos (SVM, √Årbol de decisi√≥n, Random Forest, Regresi√≥n Log√≠stica ‚Äì entrenados externamente).  
   - Modelos de redes neuronales (**FNN**, **CNN**) sobre embeddings.

4. **Evaluaci√≥n**  
   - Divisi√≥n 70/15/15 estratificada.  
   - Validaci√≥n cruzada (modelos cl√°sicos).  
   - Early stopping (redes neuronales).  
   - M√©trica principal: **F1 macro** (objetivo ‚â• 0.80, ninguna categor√≠a < 0.70).

5. **Interfaz con Streamlit (esta app)**  
   - Clasificaci√≥n de un mensaje individual.  
   - Clasificaci√≥n masiva v√≠a CSV.  
   - Visualizaci√≥n de N-Gramas y T-SNE.    
   - M√≥dulo de ChatGPT especializado en atenci√≥n al cliente.
    """)

    st.subheader("Hip√≥tesis de trabajo")
    st.write("""
La hip√≥tesis es que un sistema de clasificaci√≥n autom√°tica, integrado en el flujo de atenci√≥n al cliente,
permite **administrar mejor las solicitudes**, disminuir la carga de trabajo manual y **aumentar la
satisfacci√≥n de los usuarios**, siempre respetando la normatividad en materia de datos personales y
las buenas pr√°cticas de IA responsable.
    """)

# ---------------------------------------------------------------------
# N-GRAMAS
# ---------------------------------------------------------------------
elif opcion == "N-Gramas":
    st.header("‚ú® Visualizaci√≥n de N-Gramas ‚ú®")
    
    st.subheader("Unigramas")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.image('unigrama_account.png', caption='Unigrama ‚Äì ACCOUNT', use_container_width=True)
    with col2:
        st.image('unigrama_order.png', caption='Unigrama ‚Äì ORDER', use_container_width=True)
    with col3:
        st.image('unigrama_contact.png', caption='Unigrama ‚Äì CONTACT', use_container_width=True)

    st.subheader("Unigramas y Bigramas")
    col4, col5 = st.columns(2)
    with col4:
        st.image('unigrama_refund.png', caption='Unigrama ‚Äì REFUND', use_container_width=True)
    with col5:
        st.image('bigrama_newsletter.png', caption='Bigrama ‚Äì NEWSLETTER', use_container_width=True)

    st.subheader("Bigramas")
    col6, col7, col8 = st.columns(3)
    with col6:
        st.image('bigrama_payment.png', caption='Bigrama ‚Äì PAYMENT', use_container_width=True)
    with col7:
        st.image('bigrama_feedback.png', caption='Bigrama ‚Äì FEEDBACK', use_container_width=True)
    with col8:
        st.image('bigrama_cancellation.png', caption='Bigrama ‚Äì CANCELLATION_FEE', use_container_width=True)

    st.subheader("Trigramas")
    col9, col10, col11 = st.columns(3)
    with col9:
        st.image('trigrama_delivery.png', caption='Trigrama ‚Äì DELIVERY', use_container_width=True)
    with col10:
        st.image('trigrama_invoice.png', caption='Trigrama ‚Äì INVOICE', use_container_width=True)
    with col11:
        st.image('trigrama_shipping.png', caption='Trigrama ‚Äì SHIPPING_ADDRESS / DELIVERY', use_container_width=True)

# ---------------------------------------------------------------------
# T-SNE
# ---------------------------------------------------------------------
elif opcion == "T-SNE":
    st.header("Visualizaci√≥n T-SNE ü™Ñ")
    st.write("Distribuci√≥n en 2D de las representaciones de los mensajes por categor√≠a.")
    st.image('tsne.png', caption='Visualizaci√≥n T-SNE de las categor√≠as de mensajes')

# ---------------------------------------------------------------------
# MODELOS
# ---------------------------------------------------------------------
elif opcion == "Modelos":
    st.header("Modelos de Clasificaci√≥n")
    st.write("Selecciona el modelo con el que quieres clasificar los mensajes:")

    opciones_modelo = {
        'FNN (Red neuronal densa)': 'ProyectoFnn.h5',
        'CNN (Red neuronal convolucional)': 'ProyectoCnn.h5',
        '√Årbol de decisi√≥n (DT)': 'modeloDT.pkl',
        'SVM': 'modeloSVM.pkl'
    }

    nombre_modelo = st.selectbox('ü§ñ Modelo a utilizar', list(opciones_modelo.keys()))
    ruta_modelo = opciones_modelo[nombre_modelo]

    modelo_cargado = None

# Modelos de redes neuronales (FNN / CNN)
    if "Red neuronal" in nombre_modelo:
        modelo_cargado = tf.keras.models.load_model(ruta_modelo)

# √Årbol de decisi√≥n (DT)
    elif "√Årbol" in nombre_modelo:
        try:
            modelo_cargado = joblib.load(ruta_modelo)
        except ValueError:
            st.warning(
            "‚ö†Ô∏è El modelo de √Årbol de decisi√≥n (.pkl) fue entrenado con otra versi√≥n de scikit-learn.\n\n"
            "Para esta demo, nos concentraremos en FNN, CNN y SVM."
        )
            st.stop()

# SVM 
    elif "SVM" in nombre_modelo:
        try:
            modelo_cargado = joblib.load(ruta_modelo)
        except Exception as e:
            st.warning(
            "‚ö†Ô∏è El modelo SVM no se pudo cargar en este entorno.\n"
            "Para la demo puedes usar FNN o CNN y explicar que SVM requiere reentrenarse aqu√≠."
        )
            st.stop()


    st.subheader('üåü Clasificador de comentarios üåü')
    st.write('üîç **Escribe un comentario para clasificarlo:**')

    comentario = st.text_input('Comentario', 'Escribe aqu√≠ el mensaje del cliente')

    if st.button('Clasificar') and modelo_cargado is not None:
        scores = predecir(modelo_cargado, comentario)
        st.balloons()
        st.write('### Resultados de clasificaci√≥n üéâ')
        cols = st.columns(len(scores))
        for col, (categoria, score) in zip(cols, scores.items()):
            col.metric(categoria, f"{round(score*100, 2)}%")

        indice = ['Probabilidad']
        df = pd.DataFrame(scores, index=indice)
        st.dataframe(df)

        df_plot = df.transpose().reset_index()
        df_plot.columns = ['Categor√≠a', 'Probabilidad']
        fig = px.bar(
            df_plot,
            x='Categor√≠a',
            y='Probabilidad',
            color='Categor√≠a',
            title='Probabilidad por categor√≠a'
        )
        fig.update_layout(template='plotly_dark')
        st.plotly_chart(fig, use_container_width=True)

    st.subheader("Clasificaci√≥n de archivo CSV")
    archivo = st.file_uploader("üìÑ Carga un archivo CSV con una columna 'Text'", type='csv')
    if archivo is not None and modelo_cargado is not None:
        df_csv = pd.read_csv(archivo)
        st.write('### Contenido del archivo üìë')
        st.dataframe(df_csv.head())

        if st.button('Clasificar archivo'):
            if 'Text' not in df_csv.columns:
                st.error("El CSV debe contener una columna llamada 'Text' con los mensajes de los clientes.")
            else:
                df_csv['Category'] = df_csv['Text'].apply(lambda x: predecir_batch(modelo_cargado, x))
                st.write('### Resultados de clasificaci√≥n del archivo üìä')
                st.dataframe(df_csv)

# ---------------------------------------------------------------------
# GENERADOR DE TEXTO
# ---------------------------------------------------------------------
elif opcion == "Generador de texto":
    st.header('Generador de texto')

    ruta_modelo_rnn = "ProyectoRN.h5"
    objetos_personalizados = {
        'Orthogonal': Orthogonal,
        'LSTM': CustomLSTM
    }

    modelo_rnn = tf.keras.models.load_model(
        ruta_modelo_rnn,
        custom_objects=objetos_personalizados,
        compile=False
    )

    try:
        with open('tokenizer.pkl', 'rb') as handle:
            tokenizer = pickle.load(handle)
    except ModuleNotFoundError:
        st.error(
            "‚ö†Ô∏è El archivo tokenizer.pkl fue creado con otra versi√≥n de Keras.\n"
            "Instala una versi√≥n compatible o vuelve a generar el tokenizer en este entorno."
        )
        st.stop()

    st.subheader("Generador de respuestas autom√°ticas (demo)")
    st.sidebar.header('Opciones de generaci√≥n')

    categoria = st.sidebar.selectbox(
        'Selecciona una categor√≠a (simb√≥lica, solo para contexto)',
        ['customer', 'order', 'payment', 'feedback']
    )
    num_mensajes = st.sidebar.number_input(
        'N√∫mero de mensajes a generar',
        min_value=1,
        max_value=20,
        value=5
    )
    semilla = st.sidebar.text_input('‚å®Ô∏è Texto inicial (seed)')

    if st.sidebar.button('Generar texto'):
        if not semilla:
            st.warning("Por favor escribe un texto inicial (semilla).")
        else:
            with st.spinner('Generando texto...'):
                textos_generados = generar_texto(semilla, num_mensajes, modelo_rnn, tokenizer)
            st.success('Texto generado üòÉ')
            st.write('### Resultados:')
            for i, texto in enumerate(textos_generados, 1):
                st.write(f"{i}. {texto}")

# ---------------------------------------------------------------------
# CHATGPT
# ---------------------------------------------------------------------
elif opcion == "ChatGPT":
    st.header('ChatGPT para atenci√≥n a clientes')

    archivo_key = st.file_uploader("Sube tu API key de OpenAI (archivo .txt)", type=['txt'])
    cliente = None

    if archivo_key is not None:
        openai_api_key = archivo_key.read().decode('utf-8').strip()
        os.environ['OPENAI_API_KEY'] = openai_api_key
        cliente = OpenAI(api_key=openai_api_key)

        modelo = st.selectbox(
            "Selecciona el modelo de OpenAI",
            ("gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"),
            index=0
        )

        system_prompt = """
        Eres un asistente virtual experto en atenci√≥n a clientes de una empresa.
        Atiendes dudas sobre: cuentas, pedidos, reembolsos, facturas, pagos, comentarios,
        contacto, direcciones de env√≠o, entregas, tarifas de cancelaci√≥n y newsletters.

        Debes:
        1) Contestar de forma clara, emp√°tica y √∫til.
        2) Clasificar la consulta del cliente en una de estas categor√≠as en ingl√©s:
           'ACCOUNT', 'ORDER', 'REFUND', 'INVOICE', 'PAYMENT', 'FEEDBACK', 'CONTACT',
           'SHIPPING_ADDRESS', 'DELIVERY', 'CANCELLATION_FEE', 'NEWSLETTER'.

        Si te escriben en espa√±ol, tambi√©n puedes mencionar la categor√≠a equivalente en espa√±ol:
           'CUENTA', 'PEDIDO', 'REEMBOLSO', 'FACTURA', 'PAGO', 'COMENTARIO', 'CONTACTO',
           'DIRECCI√ìN_DE_ENV√çO', 'ENTREGA', 'TARIFA_DE_CANCELACI√ìN', 'BOLET√çN'.

        Siempre indica expl√≠citamente al final la categor√≠a asignada.
        Termina con una l√≠nea amable para el cliente.

        Si te piden algo totalmente ajeno a este dominio de soporte al cliente,
        responde √∫nicamente: 'Sorry, it won't be possible!'.
        """

        consulta = st.text_input('Escribe aqu√≠ la consulta del cliente:')

        if st.button('Generar respuesta'):
            if not consulta:
                st.warning("Por favor escribe una consulta primero.")
            else:
                with st.spinner('Generando respuesta...'):
                    respuesta = cliente.chat.completions.create(
                        model=modelo,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": consulta}
                        ]
                    )
                    contenido = respuesta.choices[0].message.content
                    st.success('Respuesta generada ‚úÖ')
                    st.write(contenido)
    else:
        st.info("Sube un archivo .txt con tu API key de OpenAI para activar este m√≥dulo.")

    st.markdown(
        """
        <style>
        .stButton>button {
            background-color: #4CAF50;
            color: white;
            font-size: 20px;
            border-radius: 12px;
        }
        .stTextInput>div>div>input {
            border: 2px solid #4CAF50;
            font-size: 16px;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

# ---------------------------------------------------------------------
# MARCO LEGAL Y T√âCNICO (PARCIAL 3)
# ---------------------------------------------------------------------
elif opcion == "Marco legal y t√©cnico":
    st.header("Marco legal y t√©cnico ‚Äì Evaluaci√≥n integral del proyecto")

    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "Naturaleza jur√≠dica",
        "Datos personales (LFPDPPP)",
        "Transparencia y AI Act",
        "Sesgos y gobernanza",
        "√âtica, riesgos y conclusiones"
    ])

    # ---------------- TAB 1: Naturaleza jur√≠dica ----------------
    with tab1:
        st.subheader("Naturaleza Jur√≠dica del Sistema")
        st.markdown("""
- El sistema **clasifica mensajes**, no toma decisiones aut√≥nomas.
- Carece de voluntad: **no puede obligarse, consentir ni generar efectos jur√≠dicos directos**.
- Su uso requiere **validaci√≥n humana constante**.
- Es un sistema **asistencial**, no operativo ni decisorio.
- No puede generar obligaciones a favor de terceros ni responsabilidad por actos propios de manera aut√≥noma.
        """)

        st.subheader("Clasificaci√≥n regulatoria (UE ‚Äì AI Act)")
        st.markdown("""
- Clasificado como sistema de **‚Äúriesgo limitado‚Äù** (art. 25 AI Act).
- No impacta derechos legales o econ√≥micos de forma aut√≥noma.
- Obligaciones clave:
  - **Transparencia** ante usuarios y operadores.
  - **Informaci√≥n suficiente** para entender la salida del sistema.
  - **Gobernanza proporcional** al riesgo.
        """)

        st.subheader("Marco mexicano aplicable")
        st.markdown("""
Ante la ausencia de una ley espec√≠fica de IA en M√©xico, se toma como base:

- **Ley Federal de Protecci√≥n de Datos Personales en Posesi√≥n de los Particulares (LFPDPPP)**  
- **Responsabilidad civil y de producto**
- **Principios constitucionales de derechos humanos**

Esto permite:
- Delimitar la responsabilidad del **proveedor**, del **operador** y de la **empresa usuaria**.
- Enmarcar el uso del sistema dentro de deberes de **cuidado, diligencia y no discriminaci√≥n**.
        """)

    # ---------------- TAB 2: Protecci√≥n de datos (LFPDPPP) ----------------
    with tab2:
        st.subheader("Protecci√≥n de Datos Personales (LFPDPPP)")

        st.markdown("### Principios esenciales aplicables")
        st.markdown("""
- **Aviso de privacidad** claro y accesible.
- **Consentimiento expreso** o mediante signos inequ√≠vocos.
- Garant√≠a plena de **Derechos ARCO** (Acceso, Rectificaci√≥n, Cancelaci√≥n y Oposici√≥n).
- **Trazabilidad** del uso del sistema para:
  - Proteger al desarrollador y operadores.
  - Evidenciar buen uso frente a autoridades y usuarios.
        """)

        st.markdown("### Obligaciones del art√≠culo 19 LFPDPPP")
        st.markdown("""
**Medidas administrativas, t√©cnicas y f√≠sicas**, por ejemplo:

- Controles de acceso por **roles**.
- **Cifrado** de datos en tr√°nsito y en reposo.
- Eliminaci√≥n **segura** de datos tras su uso.
- **Minimizaci√≥n** de datos y, cuando sea posible, procesamiento local o pseudonimizado.

El aviso de privacidad debe informar:

- El **uso de IA** para clasificar mensajes.
- La existencia de un m√≥dulo de **XAI** (explicabilidad) para atender solicitudes de informaci√≥n.
- La base de licitud del tratamiento:
  - Ordenamiento jur√≠dico v√°lido,
  - Consentimiento informado,
  - O relaci√≥n jur√≠dica previa con la persona usuaria.
        """)

    # ---------------- TAB 3: Transparencia y documentaci√≥n (AI Act) ----------------
    with tab3:
        st.subheader("Transparencia y Documentaci√≥n (AI Act)")

        st.markdown("### Requisitos internacionales (art. 13, 14, 52 AI Act)")
        st.markdown("""
El sistema debe garantizar:

- Identidad del **proveedor** y del responsable.
- **Finalidad** y l√≠mites del sistema de clasificaci√≥n.
- **M√©tricas de exactitud y desempe√±o** comunicadas de forma comprensible.
- **Revisi√≥n humana garantizada** en el flujo operativo.

        """)

        st.markdown("### Implementaci√≥n en nuestro sistema")
        st.markdown("""
- Interfaz **intuitiva**, con indicadores de contexto (palabras clave, categor√≠as).
- Informaci√≥n clara sobre:
  - Qu√© hace el sistema,
  - Qu√© no hace,
  - Y c√≥mo debe usarse correctamente.
- **Manual de uso** para operadores y auditores, que incluya:
  - Prop√≥sito y alcance,
  - Limitaciones t√©cnicas,
  - Requisitos del sistema,
  - Mecanismos de revisi√≥n humana,
  - M√©tricas y umbrales de desempe√±o aceptable.
- Un m√≥dulo de **XAI** previsto para:
  - Dar trazabilidad de cada clasificaci√≥n,
  - Explicar factores que influyeron en la decisi√≥n del modelo.
        """)

    # ---------------- TAB 4: Sesgos, actualizaci√≥n y gobernanza ----------------
    with tab4:
        st.subheader("Mitigaci√≥n de Sesgos")

        st.markdown("### Riesgos potenciales")
        st.markdown("""
- Sesgos **ling√º√≠sticos**: regionalismos, variaciones dialectales, expresiones coloquiales.
- Riesgos de **discriminaci√≥n indirecta** (trato desigual a ciertos grupos).
- Riesgos legales:
  - **Responsabilidad penal** en casos extremos,
  - **Da√±o moral**,
  - **Responsabilidad civil** frente a personas afectadas.
        """)

        st.markdown("### Medidas de mitigaci√≥n implementadas")
        st.markdown("""
- **Auditor√≠a algor√≠tmica semestral**.
- Validaci√≥n cruzada para **subgrupos ling√º√≠sticos**.
- M√©tricas de **equidad** y tasas de error balanceadas entre categor√≠as.
- Identificaci√≥n y an√°lisis de **outliers** (casos at√≠picos).
- **Reporte interno** para TEVV (Testing, Evaluation, Verification and Validation) y mejora continua.
- Recomendaci√≥n de contar con una **p√≥liza de responsabilidad civil** frente a terceros.
        """)

        st.subheader("Actualizaci√≥n y Gobernanza del Sistema")
        st.markdown("### Control de versiones")
        st.markdown("""
- Registro de cada **iteraci√≥n del modelo**.
- Validaciones t√©cnicas, legales y √©ticas antes del despliegue.
- An√°lisis de impacto y evidencia de pruebas.
- Aprobaci√≥n por parte de la figura de **AI Compliance Officer**.
        """)

        st.markdown("### Post-despliegue")
        st.markdown("""
- Monitoreo de **drift** (cambio en patrones de lenguaje y datos).
- Detecci√≥n de comportamientos an√≥malos.
- Mecanismo de **rollback** para regresar a versiones estables si alguna actualizaci√≥n:
  - Degrada la exactitud,
  - Afecta la seguridad,
  - O reduce la transparencia.
        """)

    # ---------------- TAB 5: √âtica, responsabilidad y conclusiones ----------------
    with tab5:
        st.subheader("Enfoque √âtico Integral")

        st.markdown("### Documento √©tico accesible a usuarios")
        st.markdown("""
El proyecto contempla un documento √©tico que explique:

- La **visi√≥n √©tica** del sistema y los valores que lo gu√≠an:
  - Dignidad,
  - Igualdad,
  - No discriminaci√≥n,
  - Transparencia,
  - Responsabilidad social.
- Basado en:
  - La **Constituci√≥n Mexicana** (parte dogm√°tica),
  - Tratados internacionales de **derechos humanos**.
        """)

        st.markdown("### Marco √©tico operativo")
        st.markdown("""
- Uso **responsable** de datos.
- L√≠mites funcionales del sistema (solo apoyo a clasificaci√≥n, sin decisiones finales).
- **Explicabilidad m√≠nima** garantizada hacia usuarios y auditores.
- **Revisi√≥n humana obligatoria** en casos de baja confianza o alto impacto.
- Evaluaci√≥n √©tica **anual** sobre el impacto real del sistema.
- Restricciones estrictas frente a:
  - Usos prohibidos,
  - Desv√≠os de finalidad,
  - O aplicaciones que comprometan derechos fundamentales.
        """)

        st.subheader("Responsabilidad y Riesgos Jur√≠dicos")
        st.markdown("""
- El sistema **no tiene voluntad propia** ‚Üí la responsabilidad recae en:
  - Quienes lo dise√±an,
  - Quienes lo operan,
  - Y la empresa que decide implementarlo.
- Los riesgos se mitigan mediante:
  - **Transparencia reforzada**,
  - Auditor√≠as semestrales,
  - Trazabilidad documentada,
  - Medidas de seguridad robustas,
  - Revisi√≥n humana constante.

En el contexto mexicano, la ausencia de una ley espec√≠fica de IA se compensa con:

- Regulaci√≥n de **datos personales**,
- **Derechos humanos**,
- **Responsabilidad civil**,
- Normativa de **protecci√≥n al consumidor**.
        """)

        st.subheader("Conclusiones del Cumplimiento")
        st.markdown("""
- El sistema est√° razonablemente clasificado como de **riesgo limitado**.
- Cumple con las obligaciones del **AI Act** en:
  - Transparencia,
  - Gobernanza,
  - Documentaci√≥n proporcional al riesgo.
- Se encuentra alineado con la **LFPDPPP** en:
  - Aviso de privacidad,
  - Seguridad de datos,
  - Ejercicio de derechos ARCO.
- Cuenta con estrategias s√≥lidas contra sesgos, con **auditor√≠as peri√≥dicas** y m√©tricas de equidad.
- Integra un **marco √©tico operativo**, con revisi√≥n anual y enfoque en no discriminaci√≥n.
- El proyecto refleja una visi√≥n **interdisciplinaria** Derecho + Ingenier√≠a:
  - Se demuestra **cumplimiento**,  
  - **Responsabilidad**,  
  - Y **trazabilidad** t√©cnica y jur√≠dica del sistema.
        """)
